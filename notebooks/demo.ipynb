{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ”¬ TPUsight Demo\n",
        "\n",
        "**A comprehensive TPU profiler inspired by NVIDIA Nsight**\n",
        "\n",
        "This notebook demonstrates the key features of TPUsight:\n",
        "\n",
        "1. **Systolic Array Utilization** - MXU efficiency analysis\n",
        "2. **Padding/Tiling Inefficiency** - Shape optimization\n",
        "3. **Fusion Failure Explanations** - Why ops aren't fused\n",
        "4. **Dynamic Shape + Cache Profiler** - JIT recompilation tracking\n",
        "5. **Memory Traffic + Layout** - HBM bandwidth analysis\n",
        "6. **TPU Doctor** - Actionable optimization suggestions\n",
        "7. **Time Breakdown** - Compute vs memory vs compilation time\n",
        "8. **Live Profiling** - Real-time monitoring with alerts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install TPUsight (run once)\n",
        "# !pip install -e ..\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "\n",
        "from tpusight import TPUsight\n",
        "\n",
        "print(f\"JAX version: {jax.__version__}\")\n",
        "print(f\"Devices: {jax.devices()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Usage\n",
        "\n",
        "Create a profiler and trace your JAX functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create profiler instance\n",
        "profiler = TPUsight(session_name=\"demo\")\n",
        "\n",
        "print(profiler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define some JAX functions to profile\n",
        "\n",
        "@profiler.trace\n",
        "def efficient_matmul(x, w):\n",
        "    \"\"\"Matmul with TPU-friendly dimensions (multiples of 128).\"\"\"\n",
        "    return jnp.dot(x, w)\n",
        "\n",
        "@profiler.trace\n",
        "def inefficient_matmul(x, w):\n",
        "    \"\"\"Matmul with poor dimensions for TPU.\"\"\"\n",
        "    return jnp.dot(x, w)\n",
        "\n",
        "@profiler.trace\n",
        "def mlp_layer(x, w1, w2, b1, b2):\n",
        "    \"\"\"Simple MLP layer with activation.\"\"\"\n",
        "    h = jnp.dot(x, w1) + b1\n",
        "    h = jax.nn.gelu(h)\n",
        "    return jnp.dot(h, w2) + b2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test data with different shapes\n",
        "key = random.PRNGKey(42)\n",
        "\n",
        "# Efficient shapes (multiples of 128)\n",
        "x_good = random.normal(key, (256, 512))\n",
        "w_good = random.normal(key, (512, 256))\n",
        "\n",
        "# Inefficient shapes (not aligned to 128)\n",
        "x_bad = random.normal(key, (100, 200))\n",
        "w_bad = random.normal(key, (200, 50))\n",
        "\n",
        "# MLP weights\n",
        "w1 = random.normal(key, (512, 1024))\n",
        "w2 = random.normal(key, (1024, 512))\n",
        "b1 = jnp.zeros(1024)\n",
        "b2 = jnp.zeros(512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the profiled functions\n",
        "print(\"Running efficient matmul...\")\n",
        "for _ in range(5):\n",
        "    result1 = efficient_matmul(x_good, w_good)\n",
        "\n",
        "print(\"Running inefficient matmul...\")\n",
        "for _ in range(5):\n",
        "    result2 = inefficient_matmul(x_bad, w_bad)\n",
        "\n",
        "print(\"Running MLP layer...\")\n",
        "for _ in range(3):\n",
        "    result3 = mlp_layer(x_good, w1, w2, b1, b2)\n",
        "\n",
        "print(f\"\\nProfiled {profiler.profile_data.total_ops} operations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Dashboard\n",
        "\n",
        "Launch the full interactive dashboard:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "# Generate and display the report inline\n",
        "profiler.export(\"tpu_report.html\", format=\"html\")\n",
        "\n",
        "with open(\"tpu_report.html\", \"r\") as f:\n",
        "    html_content = f.read()\n",
        "\n",
        "display(HTML(html_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the interactive dashboard\n",
        "profiler.dashboard()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Individual Analyzer Examples\n",
        "\n",
        "You can also access each analyzer individually:\n",
        "\n",
        "### Systolic Array Utilization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze MXU utilization\n",
        "systolic_analysis = profiler.systolic.analyze()\n",
        "\n",
        "if systolic_analysis['status'] == 'ok':\n",
        "    metrics = systolic_analysis['metrics']\n",
        "    print(f\"Overall MXU Utilization: {metrics.overall_utilization:.1f}%\")\n",
        "    print(f\"Total MatMul Operations: {metrics.total_matmul_ops}\")\n",
        "    print(f\"Low Efficiency Operations: {metrics.low_util_ops}\")\n",
        "    print(f\"Wasted FLOPS: {metrics.wasted_flops:,}\")\n",
        "    \n",
        "    print(\"\\nEfficiency Distribution:\")\n",
        "    for bucket, count in metrics.efficiency_buckets.items():\n",
        "        print(f\"  {bucket}: {count} ops\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padding Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze padding inefficiency\n",
        "padding_analysis = profiler.padding.analyze()\n",
        "\n",
        "if padding_analysis['status'] == 'ok':\n",
        "    metrics = padding_analysis['metrics']\n",
        "    print(f\"Average Padding Waste: {metrics.total_wasted_compute_pct:.1f}%\")\n",
        "    print(f\"Critical Shapes (>30% waste): {metrics.critical_ops}\")\n",
        "    print(f\"Warning Shapes (10-30% waste): {metrics.warning_ops}\")\n",
        "    \n",
        "    print(\"\\nWorst Shapes:\")\n",
        "    for op in metrics.worst_operations[:3]:\n",
        "        print(f\"  {op['name']}: {op['shape']} -> {op['waste_pct']:.1f}% waste\")\n",
        "        if op.get('recommendation'):\n",
        "            print(f\"    Suggestion: {op['recommendation']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get optimal shape suggestions for a specific tensor\n",
        "suggestions = profiler.padding.suggest_optimal_shapes((100, 200))\n",
        "\n",
        "print(f\"Original shape: {suggestions['original']}\")\n",
        "print(f\"Current waste: {suggestions['original_waste_pct']:.1f}%\")\n",
        "print(\"\\nSuggestions:\")\n",
        "for s in suggestions['suggestions']:\n",
        "    print(f\"  {s['type']}: {s['shape']} - {s['description']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TPU Doctor - All Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get comprehensive diagnosis\n",
        "diagnosis = profiler.doctor.diagnose()\n",
        "\n",
        "print(f\"TPU Health Score: {diagnosis['health_score']}/100 ({diagnosis['health_status']})\")\n",
        "print(f\"\\nIssues Found:\")\n",
        "print(f\"  Critical: {diagnosis['critical_count']}\")\n",
        "print(f\"  Warnings: {diagnosis['warning_count']}\")\n",
        "print(f\"  Info: {diagnosis['info_count']}\")\n",
        "\n",
        "print(\"\\n=== Top Recommendations ===\")\n",
        "for i, rec in enumerate(diagnosis['top_recommendations'][:5], 1):\n",
        "    severity_emoji = {'critical': 'ðŸ”´', 'warning': 'ðŸŸ¡', 'info': 'ðŸ”µ'}.get(rec['severity'], 'âšª')\n",
        "    print(f\"\\n{i}. {severity_emoji} {rec['title']}\")\n",
        "    print(f\"   {rec['message']}\")\n",
        "    print(f\"   Impact: {rec['impact_estimate']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility Functions\n",
        "\n",
        "TPUsight provides helpful utility functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tpusight.utils.helpers import (\n",
        "    calculate_padding_waste,\n",
        "    estimate_mxu_utilization,\n",
        "    format_bytes,\n",
        "    format_flops,\n",
        ")\n",
        "\n",
        "# Analyze padding for a shape\n",
        "shape = (100, 200)\n",
        "padding = calculate_padding_waste(shape)\n",
        "print(f\"Shape {shape}:\")\n",
        "print(f\"  Padded to: {padding['padded_shape']}\")\n",
        "print(f\"  Waste: {padding['wasted_compute_pct']:.1f}%\")\n",
        "print(f\"  Recommendation: {padding['recommendation']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimate MXU utilization for a matmul\n",
        "# (M, K) x (K, N) = (M, N)\n",
        "m, n, k = 100, 200, 150\n",
        "mxu = estimate_mxu_utilization(m, n, k)\n",
        "\n",
        "print(f\"Matmul ({m}, {k}) x ({k}, {n}):\")\n",
        "print(f\"  MXU Utilization: {mxu['mxu_utilization_pct']:.1f}%\")\n",
        "print(f\"  Actual FLOPS: {format_flops(mxu['actual_flops'])}\")\n",
        "print(f\"  Wasted FLOPS: {format_flops(mxu['wasted_flops'])}\")\n",
        "print(f\"  Bottleneck: {mxu['bottleneck']}\")\n",
        "\n",
        "# Compare with optimal shape\n",
        "m_opt, n_opt, k_opt = 128, 256, 128\n",
        "mxu_opt = estimate_mxu_utilization(m_opt, n_opt, k_opt)\n",
        "\n",
        "print(f\"\\nOptimal Matmul ({m_opt}, {k_opt}) x ({k_opt}, {n_opt}):\")\n",
        "print(f\"  MXU Utilization: {mxu_opt['mxu_utilization_pct']:.1f}%\")\n",
        "print(f\"  Wasted FLOPS: {format_flops(mxu_opt['wasted_flops'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time Breakdown Analysis\n",
        "\n",
        "See where time is actually spent - compute, memory wait, compilation, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print formatted time breakdown\n",
        "profiler.time_breakdown.print_breakdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access detailed breakdown programmatically\n",
        "time_analysis = profiler.time_breakdown.analyze()\n",
        "\n",
        "if time_analysis['status'] == 'ok':\n",
        "    breakdown = time_analysis['breakdown']\n",
        "    pct = time_analysis['percentages']\n",
        "    \n",
        "    print(f\"Total time: {breakdown.total_time_ms:.2f} ms\")\n",
        "    print(f\"\\nTime breakdown:\")\n",
        "    print(f\"  ðŸŸ¢ Compute:        {pct['compute']:.1f}%\")\n",
        "    print(f\"  ðŸ”´ Memory Wait:    {pct['memory_wait']:.1f}%\")\n",
        "    print(f\"  ðŸŸ£ Rematerialization: {pct['rematerialization']:.1f}%\")\n",
        "    print(f\"  ðŸŸ¡ Compilation:    {pct['compilation']:.1f}%\")\n",
        "    \n",
        "    print(f\"\\nBottleneck: {time_analysis['bottleneck']}\")\n",
        "    print(f\"  {time_analysis['bottleneck_description']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Live Profiling Mode\n",
        "\n",
        "Real-time monitoring with live alerts and auto-updating metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tpusight import LiveProfiler\n",
        "\n",
        "# Create live profiler with custom alert thresholds\n",
        "live = LiveProfiler(\n",
        "    alert_thresholds={\n",
        "        \"mxu_utilization_warning\": 60.0,  # Alert if MXU < 60%\n",
        "        \"padding_waste_high\": 25.0,       # Alert if padding > 25%\n",
        "    }\n",
        ")\n",
        "\n",
        "# Register alert callback - get notified immediately!\n",
        "@live.on_alert\n",
        "def handle_alert(alert):\n",
        "    icon = {\"critical\": \"ðŸ”´\", \"warning\": \"ðŸŸ¡\", \"info\": \"ðŸ”µ\"}.get(alert.severity, \"âšª\")\n",
        "    print(f\"{icon} ALERT: {alert.message} (op: {alert.operation})\")\n",
        "\n",
        "print(\"Live profiler created with custom thresholds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define functions with live tracing\n",
        "@live.trace\n",
        "def live_efficient_matmul(x, w):\n",
        "    return jnp.dot(x, w)\n",
        "\n",
        "@live.trace  \n",
        "def live_inefficient_matmul(x, w):\n",
        "    return jnp.dot(x, w)\n",
        "\n",
        "# Start live profiling\n",
        "live.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run operations - alerts fire in real-time!\n",
        "print(\"Running efficient operations...\")\n",
        "for i in range(5):\n",
        "    _ = live_efficient_matmul(x_good, w_good)\n",
        "\n",
        "print(\"\\nRunning inefficient operations (watch for alerts!)...\")\n",
        "for i in range(5):\n",
        "    _ = live_inefficient_matmul(x_bad, w_bad)\n",
        "\n",
        "# Check current metrics\n",
        "metrics = live.get_current_metrics()\n",
        "print(f\"\\nðŸ“Š Live Metrics:\")\n",
        "print(f\"  Total ops: {metrics.total_ops}\")\n",
        "print(f\"  Ops/sec: {metrics.ops_per_second:.1f}\")\n",
        "print(f\"  MXU util: {metrics.mxu_utilization:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View alert summary\n",
        "alerts = live.get_recent_alerts(10)\n",
        "alert_counts = live.get_alert_counts()\n",
        "\n",
        "print(f\"ðŸ“‹ Alert Summary:\")\n",
        "print(f\"  Total alerts: {len(alerts)}\")\n",
        "for category, count in alert_counts.items():\n",
        "    print(f\"    {category}: {count}\")\n",
        "\n",
        "print(f\"\\nðŸš¨ Recent Alerts:\")\n",
        "for alert in alerts[-5:]:\n",
        "    print(f\"  [{alert.severity}] {alert.message}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop live profiling\n",
        "live.stop()\n",
        "\n",
        "# The collected data is compatible with TPUsight for full analysis\n",
        "print(f\"\\nCollected {live.profile_data.total_ops} operations during live session\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Live Dashboard (Works in Colab/Cursor!)\n",
        "\n",
        "A simple HTML-based live dashboard that updates in real-time - no widgets required:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tpusight.visualization.live_dashboard import SimpleLiveDashboard\n",
        "import time\n",
        "\n",
        "# Create a new live profiler for dashboard demo\n",
        "live_dash = LiveProfiler()\n",
        "\n",
        "@live_dash.trace\n",
        "def dash_matmul(x, w):\n",
        "    return jnp.dot(x, w)\n",
        "\n",
        "# Create the simple dashboard (works without ipywidgets!)\n",
        "dashboard = SimpleLiveDashboard(live_dash)\n",
        "\n",
        "# Start profiling and dashboard\n",
        "live_dash.start()\n",
        "dashboard.start(update_interval=0.5)  # Updates every 0.5 seconds\n",
        "\n",
        "print(\"Dashboard started! Run the next cell to generate operations...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run operations - watch the dashboard update in real-time!\n",
        "print(\"Running operations... watch the dashboard above update!\")\n",
        "\n",
        "for i in range(20):\n",
        "    # Mix of efficient and inefficient operations\n",
        "    if i % 3 == 0:\n",
        "        _ = dash_matmul(x_bad, w_bad)  # Inefficient - will trigger alerts\n",
        "    else:\n",
        "        _ = dash_matmul(x_good, w_good)  # Efficient\n",
        "    time.sleep(0.2)  # Slow down so you can see updates\n",
        "\n",
        "print(\"Done! Check the dashboard for results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop the live dashboard when done\n",
        "dashboard.stop()\n",
        "live_dash.stop()\n",
        "\n",
        "print(\"Live session ended!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Profile your own models** - Use `@profiler.trace` or `with profiler.trace_context()`\n",
        "2. **Check the dashboard** - `profiler.dashboard()` for interactive analysis\n",
        "3. **Use live profiling** - `LiveProfiler` for real-time monitoring during training\n",
        "4. **Analyze time breakdown** - `profiler.time_breakdown.print_breakdown()` to see where time goes\n",
        "5. **Follow recommendations** - Address critical issues first\n",
        "6. **Iterate** - Profile again after optimizations to measure improvement\n",
        "\n",
        "For more information, see the [README](../README.md).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
